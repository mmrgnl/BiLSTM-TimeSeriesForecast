# Проект: Прогнозирование данных с использованием модели BiLSTM

Этот проект направлен на прогнозирование временных рядов с использованием модели **BiLSTM** (Bidirectional LSTM). Модель обучена на данных, состоящих из различных признаков и целевой переменной, для которой требуется выполнить прогнозирование.

---

## Описание данных

Данные включают следующие столбцы:

- **`obs_id`**: Идентификатор наблюдения.
- **`SiteId`**: Идентификатор местоположения.
- **`Timestamp`**: Временная метка (в формате `YYYY-MM-DDTHH:MM:SS+00:00`).
- **`ForecastId`**: Идентификатор прогноза.
- **`Value`**: Целевая переменная, для которой выполняется прогнозирование.

---

## Датасет

Данный проект использует [Building Sites Power Consumption Dataset](https://www.kaggle.com/datasets/arashnic/building-sites-power-consumption-dataset/data), доступный на Kaggle.

---

## Формат данных

Входные данные имеют размерность `(samples, timesteps, features)`.  
Целевая переменная (выходные данные) представлена в формате `(samples, 1)`.

Пример:  
- `X_train`: трёхмерный массив, где каждый элемент содержит временные ряды для отдельного наблюдения.  
- `y_train`: одномерный массив значений целевой переменной.

---

## Предобработка данных

1. **Загрузка данных**: Данные загружаются из файлов `X_train.csv`, `Y_train.csv`, `X_test.csv`, `Y_test.csv`.
2. **Преобразование временных меток**: Временные метки в столбце `Timestamp` преобразуются в числовой формат.
3. **Масштабирование**: Все числовые признаки нормализуются для улучшения обучения.
4. **Удаление выбросов**: Строки с аномальными значениями (например, `Value` > 100,000) удаляются.
5. **Добавление временной оси**: Для подачи данных в LSTM они преобразуются в формат `(samples, timesteps, features)`.

Пример кода:

```python
X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])
X_test = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])
```
# BiLSTM Модель для Прогнозирования Временных Рядов

Эта модель разработана для прогнозирования временных рядов с использованием двунаправленных LSTM (Bidirectional LSTM). Структура модели позволяет эффективно учитывать как прошлые, так и будущие временные зависимости, что улучшает качество предсказаний.

---

## Архитектура модели

Модель состоит из следующих слоев:

1. **Входной слой**:
   - Определяет форму входных данных (`input_shape`).
   - Ожидаемый формат: `(timesteps, features)`.

2. **BiLSTM слой с возвратом последовательностей**:
   - **Размер слоя**: 64 скрытых нейрона.
   - **Функция активации**: ReLU.
   - Возвращает последовательности для передачи их в следующий рекуррентный слой.
   - **Задача**: Извлечение временных зависимостей в обоих направлениях (вперед и назад).

3. **Dropout**:
   - Уровень отключения: 20%.
   - **Задача**: Предотвращение переобучения путем случайного отключения нейронов во время обучения.

4. **BiLSTM слой без возврата последовательностей**:
   - **Размер слоя**: 32 скрытых нейрона.
   - **Функция активации**: ReLU.
   - Возвращает только последнюю временную точку для дальнейшей обработки.
   - **Задача**: Углубленный анализ временных данных.

5. **Dropout**:
   - Уровень отключения: 20%.

6. **Полносвязный слой (Dense)**:
   - **Размер слоя**: 32 нейрона.
   - **Функция активации**: ReLU.
   - **Задача**: Преобразование извлеченных признаков для подготовки к финальному предсказанию.

7. **Выходной слой (Dense)**:
   - **Размер слоя**: 1 нейрон.
   - **Функция активации**: Отсутствует (линейная активация по умолчанию).
   - **Задача**: Предсказание целевой переменной.

---

## Пример кода

```python
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Input, Bidirectional, LSTM, Dense, Dropout

# Определение архитектуры модели
model = Sequential([
    Input(shape=input_shape),  # Входной слой
    Bidirectional(LSTM(64, return_sequences=True, activation='relu')),  # BiLSTM слой с возвратом последовательностей
    Dropout(0.2),                                                 # Dropout для предотвращения переобучения
    Bidirectional(LSTM(32, activation='relu')),                   # BiLSTM слой без возврата последовательностей
    Dropout(0.2),
    Dense(32, activation='relu'),                                 # Полносвязный слой
    Dense(1)                                                      # Выходной слой
])

## Обучение модели
Оптимизатор: Adam с ограничением градиента (clipvalue=1.0).
Функция потерь: MSE (Mean Squared Error).
Ранняя остановка: Используется EarlyStopping для предотвращения переобучения.
### Пример кода:
```python
early_stopping = EarlyStopping(
    monitor='val_loss',
    patience=10,
    restore_best_weights=True,
    verbose=1
)
model.compile(optimizer=Adam(learning_rate=0.001, clipvalue=1.0), loss='mse', metrics=['mae'])
model.fit(X_train, y_train, epochs=50, batch_size=64, validation_split=0.2, callbacks=[early_stopping])
```

---

## Тестирование модели
После обучения модель сохраняется и может быть протестирована на новых данных:

```python
model = tf.keras.models.load_model('bilstm_model.h5')
y_pred = model.predict(X_test)

test_loss, test_mae = model.evaluate(X_test, y_test, verbose=1)
print(f'Test Loss: {test_loss:.4f}, Test MAE: {test_mae:.4f}')
```
## Для визуализации:

```python
plt.figure(figsize=(10, 6))
plt.plot(y_test[:100], label="True Values", color='blue')
plt.plot(y_pred[:100], label="Predicted Values", color='red')
plt.legend()
plt.title('True vs Predicted values')
plt.show()
```

--- 
## Метрики оценки
Для оценки модели используется MAE:

MAE (Mean Absolute Error): Средняя абсолютная ошибка между реальными и предсказанными значениями.

```python
mae = mean_absolute_error(y_test, y_pred)

print(f'MAE: {mae:.4f}')
```
